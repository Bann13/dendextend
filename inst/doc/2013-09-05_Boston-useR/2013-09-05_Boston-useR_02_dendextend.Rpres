Creating beautiful trees of clusterings with R - dendextend
==============================================
author: Tal Galili
date: 2013-09-05
transition: none
transition-speed: fast
autosize: false
width: 1940
height: 1200

Boston-useR

```{r setup, include=FALSE, echo=FALSE}
require(knitr)
opts_chunk$set(cache=TRUE, fig.align='center')
options(digits = 3)
purl("2013-09-05_Boston-useR_02_dendextend.Rpres")
```




dendrogram: cons and pros
================================================================
incremental: false
left: 50%

dis-advantages
--------------

- **No statistical methods**

- **Terrible Speed**
(recursion in R)


***

advantages
--------------

- **Many methods**
(including as.dendrogram)

- **Flexibility in plotting**

- **Beyond binary trees**

- **"simple" data structure**
(a list of lists with attributes)

-  **Extensively used** in packages:
   -  {latticeExtra}: dendrogramGrob.
   -  {labeltodendro}: colorplot.
   -  {bclust}: bclust.
   -  {ggdendro}: dendro_data.
   -  {Heatplus}: annHeatmap2.
   -  {sparcl}: ColorDendrogram.


{dendextend}: extending dendrograms in R
================================================================
type: section
left: 60%

Credits:
-------------

```{r , echo = FALSE}
cat(packageDescription("dendextend")$Author)
cat("Yoav Benjamini")
```





Motivation for {dendextend}
------------------------------

-  Many methods already exists
-  as.dendrogram method for converting hclust and phylo objects
-  Conceptually easy to extend

   
***


```{r, echo=FALSE, fig.width=15, fig.height=10, results='asis'}
library(dendextend)
cat("dendextend has", length(ls("package:dendextend")), "functions\n") # lsf.str

require(mvbutils)
foodweb_dend <- foodweb( where="package:dendextend",plotting=FALSE)
set.seed(24262)
require(igraph)
graph_dend=graph.adjacency(foodweb_dend$funmat)
par(cex = 1.15)
plot(graph_dend, layout=layout.kamada.kawai, vertex.size = 0)
```


Accessing/Manipulating dendrogram elements
================================================================
type: sub-section

Data:

```{r}
data(precip)
precip_data <- 
   round(precip[c("Boston", "New York", "Nashville", "Miami" , "Washington")])
DIST <- dist(precip_data, diag=TRUE)
# create an heirarchical clustering object
hc <- hclust(DIST, "single") 

dend <- rev(as.dendrogram(hc))
t(t(sort(precip_data)))
```

***

Figure:

```{r, fig.height=10, fig.width=10}
par(cex = 2, lwd = 2) 
# notice how it effects the plot!
plot(dend, las = 2)
```


Leaves and branches attributes
================================================================

```{r}
require(dendextend)
nleaves(dend)
nnodes(dend)
get_nodes_attr(dend, "height")
get_nodes_attr(dend, "members")
labels_colors(dend)
```

***

Figure:

```{r, fig.height=10, fig.width=10}
par(cex = 2, lwd = 2, las = 2) 
# notice how it effects the plot!
plot(dend)
```



Colors - for leaves
================================================================

**Color leaves**:
```{r, warning=FALSE}
require(colorspace)
dend2 <- dend
labels(dend2) <- abbreviate(labels(dend2),5)
labels_colors(dend2) <- rainbow_hcl(nleaves(dend2))
```

```{r, fig.height=10, fig.width=10}
par(cex = 2, lwd = 2, las = 2) 
plot(dend2)   
```

***

Old figure:

```{r, fig.height=10, fig.width=10}
par(cex = 2, lwd = 2, las = 2) 
plot(dend)   
```



Colors - for branches
================================================================
**Color leaves**:
```{r, warning=FALSE}
require(colorspace)
dend2 <- dend
labels(dend2) <- abbreviate(labels(dend2),5)
labels_colors(dend2) <- rainbow_hcl(nleaves(dend2))
```

```{r, fig.height=10, fig.width=10}
par(cex = 2, lwd = 2, las = 2) 
plot(dend2)   
```

***

**Color branches**:
```{r, fig.height=10, fig.width=10}
dend3 <- color_branches(dend2, k=3)
par(cex = 2, lwd = 2, las = 2) 
plot(dend3)   
abline(h=3, col = 3, lty = 2)
```

Color locations - for leaves and branches
================================================================

Color locations

```{r, warning=FALSE}

data.frame(
node_label=get_nodes_attr(dend, "label"),
edgePar_col=unlist(get_nodes_attr(dend, "edgePar")),
label_col=unlist(get_nodes_attr(dend, "nodePar")) )
# NA's are for the root and the left branch
```

***

**Color branches and leaves**:
```{r, fig.height=10, fig.width=10}
par(cex = 2, lwd = 2, las = 2) 
plot(dend3)   

abline(h=3, col = 3, lty = 2)
```


Hanging
========================================


```{r, fig.height=10, fig.width=10}
dend4 <- hang.dendrogram(dend3)

par(cex = 2, lwd = 2, las = 2)
plot(dend4)   
```


***

**Color branches and leaves**:
```{r, fig.height=10, fig.width=10}
par(cex = 2, lwd = 2, las = 2) 
plot(dend3)   

abline(h=3, col = 3, lty = 2)
```



Rotating
========================================


```{r, fig.height=10, fig.width=10}


par(cex = 2, lwd = 2, las = 2)
plot(dend4)   
```

***


```{r, fig.height=10, fig.width=10}




dend5 <- rotate(dend4, c(4, 1:3, 5))
par(cex = 2, lwd = 2, las = 2)
plot(dend5)   
```





Unbranching 
========================================

```{r, fig.height=10, fig.width=10}
dend6 <- unbranch(dend5)

par(cex = 2, lwd = 2, las = 2) 
plot(dend6) 
```

```{r}
# as.hclust(dend) is not longer possible...
```



***


```{r, fig.height=10, fig.width=10}




dend5 <- rotate(dend4, c(4, 1:3, 5))
par(cex = 2, lwd = 2, las = 2)
plot(dend5)   
```





Trimming
========================================

```{r, fig.height=10, fig.width=10}
dend6 <- unbranch(dend5)

par(cex = 2, lwd = 2, las = 2) 
plot(dend6) 
```


***


```{r, fig.height=10, fig.width=10}
dend7 <- trim(dend6, c("Wshng", "NwYrk")) 

par(cex = 2, lwd = 2, las = 2) 
plot(dend7) 
```




k-clustering: cutree
========================================

Three clusters:

```{r}
cutree(dend7 , k=3)
cutree(dend7 , k=3,order_clusters_as_data=FALSE)
args(cutree.dendrogram)
```


***

```{r, fig.height=10, fig.width=10}



par(cex = 2, lwd = 2, las = 2) 
plot(dend7)  
```







Iris dataset- a quick example
========================================
left: 50%

**Iris dataset:** - 150 items, 50 from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimetres.


```{r,  fig.height = 13, fig.width=13,echo=FALSE}
data(iris)
require(colorspace)

species_col <- rev(rainbow_hcl(3))[as.numeric(iris[,5])]
# species_col[c(107,71)] <- "red" # highlight the two extreme cases we mentioned
# species_pch <- rep(1, length(species_col))
# species_pch[c(107,71)] <- 19 # highlight the two extreme cases we mentioned
species_col[c(107,71)] <- "black"

pairs(iris[,-5],cex.labels=4,
   col = species_col, pch=19,
      cex = 3.5)

```


***

```{r iris_colored_branches, fig.height = 15, fig.width=10, echo=FALSE}
par(cex = 1.5)

require(colorspace)

data(iris) 
d_iris <- dist(iris[,-5]) # method="man" # is a bit better
hc_iris <- hclust(d_iris, method = "complete")
# labels(hc_iris) # no labels, because "iris" has no row names
dend_iris <- as.dendrogram(hc_iris)
# is.integer(labels(dend_iris)) # this could cause problems...

iris_species <- rev(levels(iris[,5]))
dend_iris <- color_branches(dend_iris,k=3, groupLabels=iris_species)
# is.character(labels(dend_iris)) # labels are no longer "integer"

# have the labels match the real classification of the flowers:
labels_colors(dend_iris) <-
   rainbow_hcl(3)[sort_levels_values(
      as.numeric(iris[,5])[order.dendrogram(dend_iris)]
   )]

# We'll add the flower type
labels(dend_iris) <- paste(as.character(iris[,5])[order.dendrogram(dend_iris)],
                           "(",labels(dend_iris),")", 
                           sep = "")

dend_iris <- hang.dendrogram(dend_iris,hang_height=0.1)

# reduce the size of the labels:
dend_iris <- assign_values_to_leaves_nodePar(dend_iris, 0.5, "lab.cex")

dend_pch <- rep(NA, 150)
dend_pch[c(107,71)] <- 19
dend_pch <- dend_pch[order.dendrogram(dend_iris)]
dend_iris <- assign_values_to_leaves_nodePar(dend_iris, dend_pch, "pch")

par(mar = c(3,3,3,7))
plot(dend_iris, 
     main = "Clustered Iris dataset ('complete')
     (the labels give the true flower species)", 
     horiz =  TRUE,  nodePar = list(cex = .007))
legend("topleft", legend = iris_species, fill = rainbow_hcl(3), cex = 2)

```



Tanglegram plot: visually comparing two trees
================================================================
type: sub-section

```{r first_tanglegram, echo=FALSE, fig.height = 15, fig.width=20}

hc1 <- hclust(dist(iris[,-5]), "com")
hc2 <- hclust(dist(iris[,-5]), "single")
dend1 <- as.dendrogram(hc1)
dend2 <- as.dendrogram(hc2)

lines_col_true <- rainbow_hcl(3)[sort_levels_values(
      as.numeric(iris[,5])[order.dendrogram(dend_iris)]
   )]

tanglegram(dend1 , rev(dend2), 
           cex_main=3,
           cex_main_left=5,
           cex_main_right=5,
           color_lines=lines_col_true,
           main_left= "hclust complete", main_right="hclust single", main = "(true clusters)",
           lab.cex = .5, edge.lwd = 2, margin_inner= 3, 
           type = "r", center = TRUE, k_branches = 3
           )
```



Tanglegram plot has MANY options
===========================================


```{r}
args(dendextend:::tanglegram.dendrogram)
```
When producing many consequtive plots - it is better to use the dendrograms after adjustment (as returned by "tanglegram").


Tanglegram plot: a simple example
=====================================================
left: 50%

**Simple Data**:

```{r, warning=FALSE}
DIST <- dist(c(1,2,4,5), diag=TRUE)
# create an heirarchical clustering object
hc1 <- hclust(DIST, "single") 
dend1 <- as.dendrogram(hc1)
dend1 <- color_labels(dend1)
labels(dend1) <- LETTERS[1:4]
dend2 <- rotate(dend1, order=c(1,2,4,3))
dend2_worst <- rev(dend1)
```


**Measuring entanglement**

- Often measured as the number of line-crossings.
- We measure it as the sum of the L-norm difference between the ranks of labels of the two trees (devided by the worst case).

In our case:

```{r}
entanglement(dend1,dend2, L = 1.5)
```




***

Tanglegram plots:

```{r simple_tanglegram_1, fig.height=7, fig.width = 8}
tanglegram(dend1, dend2, lab.cex = 2, edge.lwd = 7, margin_inner= 4, color_lines = c(3,3,2,2), main = "Our data")
```


Measuring entanglement (step-by-step): L=1.5
=====================================================
left: 50%


```{r}
abs_rank_diff <- abs(c(1:4)-c(1,2,4,3))
abs_rank_diff
L<-1.5
L_norm <- abs_rank_diff^L
sum_L_norm <- sum(L_norm)
worst_case <- sum((abs(c(1:4)-c(4:1)))^L)
sum_L_norm
worst_case
sum_L_norm / worst_case
```

```{r}
entanglement(dend1,dend2)
```


***

Tanglegram plots:

```{r simple_tanglegram_1, fig.height=3, fig.width = 8, echo=FALSE}
```


```{r simple_tanglegram_1_worst_case, fig.height=7, fig.width = 8, echo=FALSE}
tanglegram(dend1, dend2_worst, lab.cex = 2, edge.lwd = 7, margin_inner= 4, color_lines = c(2,2,2,2), main = "Worst case")
```





Measuring entanglement (step-by-step): L=0
=====================================================
left: 50%

When using L=0, it is (mostly) the percent of non-streight lines:

```{r}
abs_rank_diff <- abs(c(1:4)-c(1,2,4,3))
abs_rank_diff
L<-0
L_norm <- abs_rank_diff^L
sum_L_norm <- sum(L_norm)
worst_case <- sum((abs(c(1:4)-c(4:1)))^L)
sum_L_norm
worst_case
sum_L_norm / worst_case
```

```{r}
entanglement(dend1,dend2, L = 0)
```

***

Tanglegram plots:

```{r simple_tanglegram_1, fig.height=7, fig.width = 8, echo=FALSE}
```


```{r simple_tanglegram_1_worst_case, fig.height=7, fig.width = 8, echo=FALSE}
```


Untangaling tanglegrams: random flip (once)
=====================================================
left: 50%

Optimizing rotation is an NP-hard problem!

Let us do a naive **random search** over one shuffle of the right trees:


```{r simple_tanglegram_one_shuffle_1, fig.height=7, fig.width = 8}

set.seed(1112) # always set this first!
dend2_shuffle <- shuffle(dend2)
tanglegram(dend1, dend2_shuffle, lab.cex = 2, edge.lwd = 7, margin_inner= 4, color_lines = c(2,2,3,3), main = "Different - but NOT better")

```



***

Tanglegram plots:

```{r simple_tanglegram_1, fig.height=7, fig.width = 8, echo=FALSE}
```

```{r simple_tanglegram_1_worst_case, fig.height=7, fig.width = 8, echo=FALSE}
```


Untangaling tanglegrams: random flip (many times)
=====================================================
left: 50%

Naive **random search** over MANY shuffles of BOTH trees:



```{r simple_tanglegram_random_search_1, fig.height=7, fig.width = 8}

set.seed(65168)
dend12 <- untangle_random_search(dend1, dend2, R=10)
tanglegram(dend12[[1]] , dend12[[2]], lab.cex = 2, edge.lwd = 7, margin_inner= 4, color_lines = rep(3,4), main = "Problem solved")

```



***

Tanglegram plots:

```{r simple_tanglegram_1, fig.height=7, fig.width = 8, echo=FALSE}
```

```{r simple_tanglegram_1_worst_case, fig.height=7, fig.width = 8, echo=FALSE}
```




Statistical inference on the similarity of two trees
================================================================
type: sub-section













