Creating beautiful trees of clusterings with R - intro
==============================================
author: Tal Galili
date: 2013-09-05
transition: none
transition-speed: fast
autosize: false
width: 1940
height: 1200

Boston-useR

```{r setup, include=FALSE, echo=FALSE}
require(knitr)
opts_chunk$set(cache=TRUE, fig.align='center')
options(digits = 3)
purl("2013-09-05_Boston-useR_01_intro.Rpres")
```


Intro to heirarchical clustering in R
================================================================
type: section

## -  hclust objects in R
## -  dendrogram objects in R


hclust objects in R
================================================================
type: sub-section





hclust: precip data-set
================================================================
left: 60%

**precip**: The average amount of rainfall (precipitation) in inches for three US cities in 1975.


**Code:** 

```{r precip_subset_data_prep, echo = TRUE, eval = TRUE}
data(precip)
precip_data <- 
   round(precip[c("Boston", "New York", "Nashville")])
DIST <- dist(precip_data, diag=TRUE)
# create an heirarchical clustering object
hc <- hclust(DIST, method = "single") 
```

**Data:** 
```{r, echo = FALSE}
print(precip_data)
```



**Matrix of euclidean distances:**

```{r, echo = FALSE}
print(DIST)
```



***

**Dendrogram:**

```{r precip_subset__hclust_single_plot, echo = TRUE, fig.height=9, eval = TRUE}
par(cex=1.14, cex.lab = 1.2, lwd = 4,las = 1)
plot(hc, hang = -1) 
abline(h = c(2,4), 
       lty = 2, col = 2, lwd = 2)
```










hclust: k-clustering
================================================================
incremental: false
left: 60%

**R Code**:

Getting the clusters:

```{r }
cutree(hc, k = 2)
```
   
```{r }
cutree(hc, h = 3.5)
```


***


**Dendrogram:** (with rectangles)



```{r precip_subset__hclust_single_plot_rect,echo = TRUE, fig.height=9, eval = TRUE}
par(cex=1.14, cex.lab = 1.2, lwd = 4,las = 1)
plot(hc, hang = -1) 

abline(h = 3.5, col = 2, lty = 2)
rect.hclust(hc, k = 2, border = 3)
# No - xlim didn't fix this...
```






hclust: other clustering algorithms
================================================================

```{r ,echo = FALSE, fig.height=9, fig.width=25, eval = TRUE}
x <- c(1:3, 5)
names(x) <- c(1:3, 5) # We MUST add names...
print(x)
x_dist <- dist(x)
par(mfrow = c(1,3), cex=1.14, cex.lab = 1.2, lwd = 4,cex.main=2)
plot(hclust(x_dist, method = "single"), main = "single", hang = -1) 
plot(hclust(x_dist, method = "complete"), main = "complete", hang = -1) 
plot(hclust(x_dist, method = "average"), main = "average", hang = -1) 
```





hclust: pros and cons
================================================================
incremental: false
left: 50%

advantages
----------

- **Diversity in statistical methods:**

"single", "complete", "average", "ward", "mcquitty", "median" or "centroid".


- **Speed:**

```{r hclust_speed_measurment}
DIST <- dist(rnorm(4000))
system.time(hc2 <- hclust(DIST))
system.time(cutree(hc2, k = 4))
```



***

dis-advantages
--------------

- **Limited flexibility in plotting:**

- **Only binary trees**

- **"Complex" data structure:**
(see "merge")

```{r}
str(hc)
```




dendrogram objects in R
================================================================
type: sub-section



hclust -> dendrogram: dendrogram structure
================================================================
left: 70%
incremental: false


```{r }
data(precip)
precip_data <- 
   round(precip[c("Boston", "New York", "Nashville")])
DIST <- dist(precip_data, diag=TRUE)
# create an heirarchical clustering object
hc <- hclust(DIST, "single") 
#########################
##### hclust to dend ####
#########################
dend <- as.dendrogram(hc)

print(dend)
str(dend)
```

***

**Dendrogram:**
```{r precip_dend_plot_1, echo=FALSE, fig.height=9}
par(cex=2.5, lwd = 4,las = 1)
plot(dend) 
```



hclust -> dendrogram: dendrogram structure
================================================================
left: 70%
incremental: false

```{r}
str(unclass(dend))
```


***
**Dendrogram:**
```{r precip_dend_plot_1, echo=FALSE, fig.height=9}
```


dendrogram: what can we do with them? 
================================================================
left: 70%
About 11 things:

```{r, cache=FALSE}
as.matrix(methods(class="dendrogram"))
```

***
**Dendrogram:**
```{r precip_dend_plot_1, echo=FALSE, fig.height=9}
```


dendrogram: Extracting elements
================================================================
left: 70%


**labels**:

```{r}
labels(dend)
```

**order.dendrogram**:
```{r}
order.dendrogram(dend)
```
(values for ordering original data to have tree order)


Using **[[**, **str** and **print**:

```{r}
print(str(dend[[2]]))
```


***
**Dendrogram:**
```{r precip_dend_plot_1, echo=FALSE, fig.height=9}
```



dendrogram: Tree cutting/merging
================================================================
left: 70%

**cut:**

(like cutree with only h)

```{r}
cut(dend,h=50)
```

**merge:**

```{r}
cut_dend <- cut(dend,h=3)$lower
# now let's get our tree back:
merge(cut_dend[[1]], cut_dend[[2]], height = 4)
```

***
**Dendrogram:**
```{r precip_dend_plot_2, echo=FALSE, fig.height=9}
par(cex=2.5, lwd = 4,las = 1)
plot(dend) 
abline(h = 3, lty = 2, col = 2)
```



dendrogram: Retreiving (cophenetic) distances
================================================================
left: 70%


```{r}
ord <- order.dendrogram(dend)
DIST <- dist(precip_data[ord], diag=TRUE)
print(DIST, diag = TRUE)
coph_dend <- cophenetic(dend)
as.dist(coph_dend, diag = TRUE)
```

Notice "Nashville" and "New York" has different distances.

**Cophenetic correlation coefficient:** a measure of how faithfully a dendrogram preserves the pairwise distances between the original unmodeled data points.

```{r}
round(
   cor(DIST, coph_dend),
   2)
```


***
**Dendrogram:**
```{r precip_dend_plot_1, echo=FALSE, fig.height=9}
```


dendrogram: Plotting and changing order
================================================================

**plot** and **rev**:

```{r, fig.width=20}
par(mfrow = c(1,2))
plot(dend) # has various options
plot(rev(dend))
```

(reorder == not easy!)

dendrogram: what can we do with them?
================================================================

Plotting options
----------------------------

```{r}
args(stats:::plot.dendrogram)
```

dendrogram: Plotting options - example
================================================================


```{r, fig.width=20, fig.height=10}
par(mfrow = c(1,2), cex = 2)
plot(dend, main = "default") 
plot(dend, main = "modified",
     type = "t", center = TRUE, horiz = TRUE, 
     nodePar = list(lab.col = 4), 
     edgePar = list(col = 3 , lwd = 3)) 
```





dendrogram: Recursive functions
================================================================
left: 60%


```{r}
print_height <- function(x) { 
   print(attr(x, "height"))
   }

tmp <- dendrapply(dend,
                  print_height)
```

***
 

```{r ref.label='precip_subset__hclust_single_plot', echo = FALSE, fig.height=9, eval = TRUE}
```



dendrogram: cons and pros
================================================================
incremental: false
left: 50%

dis-advantages
--------------

- **No statistical methods**

- **Terrible Speed**
(recursion in R)


***

advantages
--------------

- **Many methods**
(including as.dendrogram)

- **Flexibility in plotting**

- **Beyond binary trees**

- **"simple" data structure**
(a list of lists with attributes)

-  **Extensively used** in packages:
   -  {latticeExtra}: dendrogramGrob.
   -  {labeltodendro}: colorplot.
   -  {bclust}: bclust.
   -  {ggdendro}: dendro_data.
   -  {Heatplus}: annHeatmap2.
   -  {sparcl}: ColorDendrogram.

